# Offline-GPT
&emsp;wifi-free local LLM interface for demonstration purposes

## Installation
  &emsp;-install Ollama from: [ollama download](https://ollama.com/download) <br>
  &emsp;-add ollama to environment variables PATH<br>
  &emsp;-pull local Phi LLM: `ollama pull phi:2.7b-chat-v2-q4_0`<br>
  &emsp;-create conda environment or virtual environment: `python -m venv <environment_name>` and activate<br>
  &emsp;-install ollama library: `pip install ollama`<br>
## Usage
  &emsp;-run program:`python app.py`<br>
  &emsp;-switch between chat window and game window using keyboard: `Ctrl+1`<br>

## Disclaimer
  &emsp;-Please note that this project is intended for educational purposes and might not be suitable for production environments. The project is provided "as is", without warranty of any kind. In no event shall the authors or copyright holders be liable for any claim, damages or other liability arising from the use of this project.<br>
